---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

I aspire to leverage the power of the physical world and computation to build multimodal human interfaces that augment the mind, body, and living environment. My work often results in products used by people across the world, in top academic conferences, and in mass media.

I lead HCI Research and Product for Usefulsensors, a spinoff with the founding Team of Tensorflow (Google Brain)- building private/locally running AI agents on low-compute hardware. using (speech, LLMs, and TTS models). Discovering cognitive, bio/wellness markers from ambient human speech.  

I earlier co-founded and led Ducere, a wearable wellness tech startup developing a haptic I/O platform for the visually impaired and elderly for fall and gait analysis (exited 2018- link 1, link 2).  and later Graviky Labs, an electrochemical carbon emissions CO2 to product venture (Forbes article, Case Study).

As a graduate research assistant at the MIT Media Lab, Massachusetts Institute of Technology I built AR gestural interfaces using transparent displays under Prof. Pattie Maes. At Hewlett-Packard Labs and Google I developed an open-source multi-projector stereoscopic (3D) multimodal gestural interface for CAD modeling (SketchUp). 

I taught Engineering Design Courses at MIT D-Lab, and MITâ€™s Global Startup Labs and co-led the Not-Profit MIT Media Lab India Initiative: a 10-day hands-on program where MIT/Harvard researchers worked with Indian students to explore new sensing technologies overlapping with real problems.

(He also loves magic, tabla, camping, bonfires, and designing new contraptions for astrophotography. In an alternate universe, he is probably undergoing an apprenticeship with some sorcerer. )
